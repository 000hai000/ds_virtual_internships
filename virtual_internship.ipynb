{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Internships Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing and Cleaning\n",
    "\n",
    "First we will import all relevant modules. We will then import our csv as a pandas dataframe for easy use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userIDs</th>\n",
       "      <th>implementation</th>\n",
       "      <th>Line_ID</th>\n",
       "      <th>ChatGroup</th>\n",
       "      <th>content</th>\n",
       "      <th>group_id</th>\n",
       "      <th>RoleName</th>\n",
       "      <th>roomName</th>\n",
       "      <th>m_experimental_testing</th>\n",
       "      <th>m_making_design_choices</th>\n",
       "      <th>m_asking_questions</th>\n",
       "      <th>j_customer_consultants_requests</th>\n",
       "      <th>j_performance_parameters_requirements</th>\n",
       "      <th>j_communication</th>\n",
       "      <th>OutcomeScore</th>\n",
       "      <th>wordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>Hello team. Welcome to Nephrotex!</td>\n",
       "      <td>2</td>\n",
       "      <td>Mentor</td>\n",
       "      <td>Introduction and Workflow Tutorial with Entran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>I'm Maria Williams. I'll be your design adviso...</td>\n",
       "      <td>2</td>\n",
       "      <td>Mentor</td>\n",
       "      <td>Introduction and Workflow Tutorial with Entran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>I'm here to help if you have any questions.</td>\n",
       "      <td>2</td>\n",
       "      <td>Mentor</td>\n",
       "      <td>Introduction and Workflow Tutorial with Entran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>Please introduce yourselves with the name you ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Mentor</td>\n",
       "      <td>Introduction and Workflow Tutorial with Entran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>5</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>I just want to make sure everyone has found th...</td>\n",
       "      <td>2</td>\n",
       "      <td>Mentor</td>\n",
       "      <td>Introduction and Workflow Tutorial with Entran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userIDs implementation  Line_ID ChatGroup  \\\n",
       "0        1              a        1     PRNLT   \n",
       "1        1              a        2     PRNLT   \n",
       "2        1              a        3     PRNLT   \n",
       "3        1              a        4     PRNLT   \n",
       "4        1              a        5     PRNLT   \n",
       "\n",
       "                                             content  group_id RoleName  \\\n",
       "0                  Hello team. Welcome to Nephrotex!         2   Mentor   \n",
       "1  I'm Maria Williams. I'll be your design adviso...         2   Mentor   \n",
       "2        I'm here to help if you have any questions.         2   Mentor   \n",
       "3  Please introduce yourselves with the name you ...         2   Mentor   \n",
       "4  I just want to make sure everyone has found th...         2   Mentor   \n",
       "\n",
       "                                            roomName  m_experimental_testing  \\\n",
       "0  Introduction and Workflow Tutorial with Entran...                       0   \n",
       "1  Introduction and Workflow Tutorial with Entran...                       0   \n",
       "2  Introduction and Workflow Tutorial with Entran...                       0   \n",
       "3  Introduction and Workflow Tutorial with Entran...                       0   \n",
       "4  Introduction and Workflow Tutorial with Entran...                       0   \n",
       "\n",
       "   m_making_design_choices  m_asking_questions  \\\n",
       "0                        0                   0   \n",
       "1                        0                   0   \n",
       "2                        0                   0   \n",
       "3                        0                   0   \n",
       "4                        0                   0   \n",
       "\n",
       "   j_customer_consultants_requests  j_performance_parameters_requirements  \\\n",
       "0                                0                                      0   \n",
       "1                                0                                      0   \n",
       "2                                0                                      0   \n",
       "3                                1                                      0   \n",
       "4                                0                                      0   \n",
       "\n",
       "   j_communication  OutcomeScore  wordCount  \n",
       "0                0             4          5  \n",
       "1                0             4         11  \n",
       "2                0             4          9  \n",
       "3                0             4         51  \n",
       "4                0             4         39  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('virtualInternshipData.csv', encoding= 'unicode_escape') #read the csv provided\n",
    "df = df.drop(\"Unnamed: 0\",axis=1) #drop the unnamed column\n",
    "df.head() #print first several rows of data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['RoleName']==\"Mentor\"][\"OutcomeScore\"].value_counts().plot(kind='bar', title='Mentor Outcome Scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, if the certain user is a mentor, they are automatically assigned an outcome score of 4 which will be irrelevant for our model because we are trying to predict the player scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['RoleName']==\"Player\"][\"OutcomeScore\"].value_counts().plot(kind='bar', title='Player Outcome Scores');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df = copy.deepcopy(df[df['RoleName']==\"Player\"]) #only get dataframe with Player\n",
    "df = df.sort_values(by=['userIDs']) #to group outcome scores later on \n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "When working with text or natural language, there are certain words that don't add any value to a sentence e.g. \"this\" and so we will need to remove these words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With stop words: hello i am brandon!\n",
      "Without stop words: hello brandon\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "\n",
    "df['content'] = df['content'].str.lower() #make all the letters lowercase for easy of use\n",
    "\n",
    "stop = stopwords.words('english') #import english stopwords from nltk \n",
    "additional_stopwords = [\"i'm\", \"i'll\", \"ill\"] #add any additional stop words not from nltk\n",
    "stop = stop + additional_stopwords\n",
    "\n",
    "df['content_without_stopwords'] = df['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) #remove all stopwords in content column\n",
    "\n",
    "df['content_without_stopwords'] = df['content_without_stopwords'].apply(lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation))) #remove all punctuation\n",
    "\n",
    "df['content_without_stopwords'] = df['content_without_stopwords'].apply(lambda x: \"\".join([i for i in x if not i.isdigit()])) #remove all digits\n",
    "\n",
    "print('With stop words: ' + df['content'][0])\n",
    "print('Without stop words: ' + df['content_without_stopwords'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>userIDs</th>\n",
       "      <th>implementation</th>\n",
       "      <th>Line_ID</th>\n",
       "      <th>ChatGroup</th>\n",
       "      <th>content</th>\n",
       "      <th>group_id</th>\n",
       "      <th>RoleName</th>\n",
       "      <th>roomName</th>\n",
       "      <th>m_experimental_testing</th>\n",
       "      <th>m_making_design_choices</th>\n",
       "      <th>m_asking_questions</th>\n",
       "      <th>j_customer_consultants_requests</th>\n",
       "      <th>j_performance_parameters_requirements</th>\n",
       "      <th>j_communication</th>\n",
       "      <th>OutcomeScore</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>content_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>6</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>hello i am brandon!</td>\n",
       "      <td>2</td>\n",
       "      <td>Player</td>\n",
       "      <td>Introduction and Workflow Tutorial with Entran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>hello brandon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>248</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>using negative and hydrophillic</td>\n",
       "      <td>2</td>\n",
       "      <td>Player</td>\n",
       "      <td>Team designs batch using 1 material</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>using negative hydrophillic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>145</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>the amount of nano tubes in the filter?</td>\n",
       "      <td>2</td>\n",
       "      <td>Player</td>\n",
       "      <td>Individuals design 5 prototypes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>amount nano tubes filter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>146</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>thank you!</td>\n",
       "      <td>2</td>\n",
       "      <td>Player</td>\n",
       "      <td>Individuals design 5 prototypes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>303</td>\n",
       "      <td>PRNLT</td>\n",
       "      <td>i think that blood cell reactivity is very imp...</td>\n",
       "      <td>2</td>\n",
       "      <td>Player</td>\n",
       "      <td>Reflection team discussion of first batch results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>think blood cell reactivity important</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  userIDs implementation  Line_ID ChatGroup  \\\n",
       "0      5        2              a        6     PRNLT   \n",
       "1    247        2              a      248     PRNLT   \n",
       "2    144        2              a      145     PRNLT   \n",
       "3    145        2              a      146     PRNLT   \n",
       "4    302        2              a      303     PRNLT   \n",
       "\n",
       "                                             content  group_id RoleName  \\\n",
       "0                                hello i am brandon!         2   Player   \n",
       "1                    using negative and hydrophillic         2   Player   \n",
       "2            the amount of nano tubes in the filter?         2   Player   \n",
       "3                                         thank you!         2   Player   \n",
       "4  i think that blood cell reactivity is very imp...         2   Player   \n",
       "\n",
       "                                            roomName  m_experimental_testing  \\\n",
       "0  Introduction and Workflow Tutorial with Entran...                       0   \n",
       "1                Team designs batch using 1 material                       0   \n",
       "2                    Individuals design 5 prototypes                       0   \n",
       "3                    Individuals design 5 prototypes                       0   \n",
       "4  Reflection team discussion of first batch results                       0   \n",
       "\n",
       "   m_making_design_choices  m_asking_questions  \\\n",
       "0                        0                   0   \n",
       "1                        0                   0   \n",
       "2                        0                   1   \n",
       "3                        0                   0   \n",
       "4                        0                   0   \n",
       "\n",
       "   j_customer_consultants_requests  j_performance_parameters_requirements  \\\n",
       "0                                0                                      0   \n",
       "1                                0                                      0   \n",
       "2                                0                                      0   \n",
       "3                                0                                      0   \n",
       "4                                0                                      0   \n",
       "\n",
       "   j_communication  OutcomeScore  wordCount  \\\n",
       "0                0             4          4   \n",
       "1                0             4          4   \n",
       "2                0             4          8   \n",
       "3                0             4          2   \n",
       "4                0             4          9   \n",
       "\n",
       "               content_without_stopwords  \n",
       "0                          hello brandon  \n",
       "1            using negative hydrophillic  \n",
       "2               amount nano tubes filter  \n",
       "3                              thank you  \n",
       "4  think blood cell reactivity important  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing\n",
    "\n",
    "In natural language processing, each document or sentence can thought of as a bag of words in the form of a list where each element is a word..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df['content_tokenized'] = df.apply(lambda row: word_tokenize(row['content_without_stopwords']), axis=1) #tokenize all the content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the document up like this is called <u>tokenizing</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'brandon']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content_tokenized'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 5569\n",
      "['product', 'differences', 'thomasdavisksuedu', 'brown', 'short', 'spotty', 'pleasing', 'revolving', 'phases', 'typing', 'scientific', 'rough', 'confusion', 'seriously', 'surfucants', 'unfinished', 'splitting', 'comparison', 'sersiously', 'hydrophilc']\n"
     ]
    }
   ],
   "source": [
    "#all words found in the content\n",
    "word_set = set().union(*df['content_tokenized'])\n",
    "print(\"Number of words: \" + str(len(word_set)))\n",
    "print(list(word_set)[:20]) #print first 20 words of word set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#splitting each sublist into all content said by each user\n",
    "user_dict = [] #creating an empty list to store all the sublist of all the words said by each user\n",
    "for idx in df['userIDs'].unique(): #loop over every unique id\n",
    "    lst = [word_tokenize(i) for i in df[df['userIDs'] == idx]['content_without_stopwords'].to_list()] #tokenize the contents of each row\n",
    "    tokenized_sents = [item for sublist in lst for item in sublist] #re-formatting \n",
    "    tokenized_sents_with_id = [idx, tokenized_sents]\n",
    "    user_dict.append(tokenized_sents_with_id) #append the sublist into the user_dict list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'brandon', 'using', 'negative', 'hydrophillic', 'amount', 'nano', 'tubes', 'filter', 'thank']\n"
     ]
    }
   ],
   "source": [
    "print(user_dict[0][1][:10]) #printing all content that user 2 said"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list where each sublist is a dictionary that counts the frequency of all the words that are used by a user\n",
    "word_dict = [] #create an empty list to store all the words used\n",
    "for i in range(len(user_dict)):\n",
    "    #creating dictionaries to keep count of the words\n",
    "    temp_word_dict = dict.fromkeys(word_set, 0)\n",
    "    word_dict.append(temp_word_dict) #append each dictionary to the word dictionary \n",
    "    \n",
    "    #count the words in the bag of words for each user\n",
    "    for word in user_dict[i][1]:\n",
    "        word_dict[i][word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('product', 2), ('differences', 0), ('thomasdavisksuedu', 0), ('brown', 0), ('short', 0), ('spotty', 0), ('pleasing', 0), ('revolving', 0), ('phases', 0), ('typing', 0)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word_dict[0].items())[:10]) #printing the first 10 dictionary words of user 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "Rather than just counting, we can use <u>TF-IDF</u>, short for term frequency-inverse document frequency to rank a word on it's importance.\n",
    "\n",
    "The <u>TF-IDF</u> score of a word $ w $ is: $ tf(w) * idf(w) $\n",
    "\n",
    "Where $ tf(w) $ = frequency of word in a document / total number of words in the document\n",
    "\n",
    "And where $ idf(w) $ = $\\log$(number of documents / number of documents that contain word $ w $)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(word_dict, user_dict):\n",
    "    tf_dict = {}\n",
    "    user_dict_count = len(user_dict)\n",
    "    for word, count in word_dict.items():\n",
    "        if user_dict_count == 0:\n",
    "            tf_dict[word] = 0\n",
    "        else:\n",
    "            tf_dict[word] = count / float(user_dict_count)\n",
    "    return tf_dict\n",
    "\n",
    "def computeIDF(doc_list):\n",
    "    import math\n",
    "    idf_dict = {}\n",
    "    n = len(doc_list)\n",
    "\n",
    "    idf_dict = dict.fromkeys(doc_list[0].keys(),0)\n",
    "    for doc in doc_list:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idf_dict[word] += 1\n",
    "\n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = math.log(n / float(val), 10)\n",
    "\n",
    "    return idf_dict\n",
    "\n",
    "def computeTFIDF(tf_user_dict, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tf_user_dict.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of TF-IDF\n",
    "\n",
    "Suppose we have two documents as listed below. The calculation of <u>TF-IDF</u> for the term \"hello\" is performed as: \n",
    "\n",
    "The <u>TF</u>, is the frequency that the word \"hello\" appears in each document. In each document, the word appears once; but as document 1 (index 0) has more words, its relative frequency is smaller.\n",
    "\n",
    "$$ tf('charge', doc1) = \\frac{1}{2} = 0.5 $$\n",
    "$$ tf('charge', doc2) = \\frac{1}{3} \\approx 0.33 $$\n",
    "\n",
    "An <u>IDF</u> accounts for the ratio of documents that include the word \"hello\". In this case, we have a total of two documents and all of them include the word \"hello\".\n",
    "\n",
    "$$ idf('charge', documents) = log(\\frac{2}{2}) = 0 $$\n",
    "\n",
    "So <u>TF-IDF</u> is 0 for the word \"hello\" implying that the word is not very informative as it appears in all documents.\n",
    "\n",
    "$$ tfidf('charge', doc1, documents) = 0.5 * 0 = 0 $$\n",
    "$$ tfidf('charge', doc2, documents) = 0.33 * 0 = 0 $$\n",
    "\n",
    "Take the word \"team\", it occurs once only in document 1:\n",
    "\n",
    "$$ tf('hydrophilic', doc1) = \\frac{0}{2} = 0 $$\n",
    "$$ tf('hydrophilic', doc2) = \\frac{1}{3} \\approx 0.33 $$\n",
    "$$ idf('hydrophilic', documents) = log(\\frac{2}{1}) \\approx 0.301 $$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$ tfidf('hydrophilic', doc1, documents) = tf('hydrophilic', doc1) * idf('hydrophilic', documents) = 0 * 0.301 = 0 $$\n",
    "$$ tfidf('hydrophilic', doc2, documents) = tf('hydrophilic', doc2) * idf('hydrophilic', documents) = 0.33 * 0.301 \\approx 0.1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charge</th>\n",
       "      <th>hydrophilic</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   charge  hydrophilic  negative\n",
       "0       1            0         1\n",
       "1       1            1         1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = word_tokenize(df['content_without_stopwords'][19])\n",
    "doc2 = word_tokenize(df['content_without_stopwords'][21])\n",
    "\n",
    "word_set_example = set(doc1).union(set(doc2))\n",
    "word_dict1 = dict.fromkeys(word_set_example, 0)\n",
    "word_dict2 = dict.fromkeys(word_set_example, 0)\n",
    "\n",
    "for word in doc1:\n",
    "    word_dict1[word] += 1\n",
    "\n",
    "for word in doc2:\n",
    "    word_dict2[word] += 1\n",
    "\n",
    "pd.DataFrame([word_dict1, word_dict2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charge\n",
      "tf for document 1: 0.5\n",
      "tf for document 2: 0.3333333333333333\n",
      "idf for documents: 0.0\n",
      "tfidf for document 1: 0.0\n",
      "tfidf for document 2: 0.0\n",
      "\n",
      "hydrophilic\n",
      "tf for document 1: 0.0\n",
      "tf for document 2: 0.3333333333333333\n",
      "idf for documents: 0.30102999566398114\n",
      "tfidf for document 1: 0.0\n",
      "tfidf for document 2: 0.10034333188799371\n"
     ]
    }
   ],
   "source": [
    "tf1_example = computeTF(word_dict1, doc1)\n",
    "tf2_example = computeTF(word_dict2, doc2)\n",
    "\n",
    "idf_example = computeIDF([word_dict1, word_dict2])\n",
    "\n",
    "tfidf1_example = computeTFIDF(tf1_example, idf_example)\n",
    "tfidf2_example = computeTFIDF(tf2_example, idf_example)\n",
    "\n",
    "word1 = \"charge\"\n",
    "print(word1)\n",
    "print(\"tf for document 1: \" + str(tf1_example[word1]))\n",
    "print(\"tf for document 2: \" + str(tf2_example[word1]))\n",
    "print(\"idf for documents: \" + str(idf_example[word1]))\n",
    "print(\"tfidf for document 1: \" + str(tfidf1_example[word1]))\n",
    "print(\"tfidf for document 2: \" + str(tfidf2_example[word1]))\n",
    "print(\"\")\n",
    "\n",
    "word2 = \"hydrophilic\"\n",
    "print(word2)\n",
    "print(\"tf for document 1: \" + str(tf1_example[word2]))\n",
    "print(\"tf for document 2: \" + str(tf2_example[word2]))\n",
    "print(\"idf for documents: \" + str(idf_example[word2]))\n",
    "print(\"tfidf for document 1: \" + str(tfidf1_example[word2]))\n",
    "print(\"tfidf for document 2: \" + str(tfidf2_example[word2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF(word_dict) #compute idf\n",
    "tfidf = [] #create empty list to append tf-idf values\n",
    "for i in range(len(user_dict)): \n",
    "    temp_tf_user_dict = computeTF(word_dict[i], user_dict[i][1]) #compute tf\n",
    "    temp_tfidf_user_dict = computeTFIDF(temp_tf_user_dict, idfs) #compute tf-idf\n",
    "    tfidf.append(temp_tfidf_user_dict) #append tf-idf values into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>differences</th>\n",
       "      <th>thomasdavisksuedu</th>\n",
       "      <th>brown</th>\n",
       "      <th>short</th>\n",
       "      <th>spotty</th>\n",
       "      <th>pleasing</th>\n",
       "      <th>revolving</th>\n",
       "      <th>phases</th>\n",
       "      <th>typing</th>\n",
       "      <th>...</th>\n",
       "      <th>contaminants</th>\n",
       "      <th>sterichindering</th>\n",
       "      <th>ray</th>\n",
       "      <th>referred</th>\n",
       "      <th>press</th>\n",
       "      <th>leggo</th>\n",
       "      <th>ss</th>\n",
       "      <th>np</th>\n",
       "      <th>retweet</th>\n",
       "      <th>outcome_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5570 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    product  differences  thomasdavisksuedu  brown  short  spotty  pleasing  \\\n",
       "2  0.002970          0.0                0.0    0.0    0.0     0.0       0.0   \n",
       "3  0.006100          0.0                0.0    0.0    0.0     0.0       0.0   \n",
       "4  0.003032          0.0                0.0    0.0    0.0     0.0       0.0   \n",
       "5  0.000000          0.0                0.0    0.0    0.0     0.0       0.0   \n",
       "6  0.000000          0.0                0.0    0.0    0.0     0.0       0.0   \n",
       "\n",
       "   revolving  phases  typing  ...  contaminants  sterichindering  ray  \\\n",
       "2        0.0     0.0     0.0  ...           0.0              0.0  0.0   \n",
       "3        0.0     0.0     0.0  ...           0.0              0.0  0.0   \n",
       "4        0.0     0.0     0.0  ...           0.0              0.0  0.0   \n",
       "5        0.0     0.0     0.0  ...           0.0              0.0  0.0   \n",
       "6        0.0     0.0     0.0  ...           0.0              0.0  0.0   \n",
       "\n",
       "   referred  press  leggo   ss   np  retweet  outcome_score  \n",
       "2       0.0    0.0    0.0  0.0  0.0      0.0              4  \n",
       "3       0.0    0.0    0.0  0.0  0.0      0.0              4  \n",
       "4       0.0    0.0    0.0  0.0  0.0      0.0              4  \n",
       "5       0.0    0.0    0.0  0.0  0.0      0.0              2  \n",
       "6       0.0    0.0    0.0  0.0  0.0      0.0              2  \n",
       "\n",
       "[5 rows x 5570 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame.from_records(tfidf) #make the matrix into a dataframe\n",
    "\n",
    "idx = [user_dict[i][0] for i in range(len(user_dict))]\n",
    "df_tfidf.index = idx\n",
    "\n",
    "outcome_score = df.drop_duplicates(subset=['userIDs'])['OutcomeScore'].to_numpy() #grab outcome score of each individual user\n",
    "df_tfidf['outcome_score'] = outcome_score\n",
    "\n",
    "df_tfidf.head() #print the first several rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling using Imbalanced-learn\n",
    "Since the dataset is so imbalanced, consisting of mainly outcome scores of 4, using metrics like `accuracy_score` can be misleading. Therefore, we need to use resampling in order to remove samples from the majority class (under-sampling) or adding more samples from the minority class (over-sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1 #initialise random_state we want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_score_count = df_tfidf['outcome_score'].value_counts()\n",
    "outcome_score_count.plot(kind='bar', title='Outcome Score Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tfidf[df_tfidf.drop(columns=['outcome_score']).columns]\n",
    "y = df_tfidf['outcome_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users after over sampling: 1125\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=random_state) #random_state to an integer to make sure examples are repeatable\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "print(\"Number of users after over sampling: \" + str(len(X_ros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_score_count = y_ros.value_counts()\n",
    "outcome_score_count.plot(kind='bar', title='Outcome Score Count after Over Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Since our current dataset has so many features, currently with 5569 columns, a technique we can use to reduce the number of features is feature selection where we reduce the number of irrelevant features in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation\n",
    "\n",
    "We check the absolute value of the Pearson’s correlation between the target and numerical features in our dataset. We keep the top n features based on this criterion.\n",
    "\n",
    "$$ r = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i - \\bar{x})^2}\\sum(y_i - \\bar{y})^2} $$\n",
    "$r$ = correlation coefficient   \n",
    "$x_i$ = values of the x-variable in a sample  \n",
    "$\\bar{x}$ = mean of the values of the x-variable  \n",
    "$y_i$ = values of the y-variable in a sample  \n",
    "$\\bar{y}$ = mean of the values of the y-variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(X, y,num_feats):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    # 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cor_feature(X, y, num_feats):\n",
    "    feature_name = list(X.columns)\n",
    "    # no of maximum features we need to select\n",
    "    cor_support, cor_feature = cor_selector(X, y, num_feats)\n",
    "    return cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 selected features\n"
     ]
    }
   ],
   "source": [
    "cor_feature = generate_cor_feature(X_ros, y_ros, 3000)\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notification',\n",
       " 'chosing',\n",
       " 'accidental',\n",
       " 'assest',\n",
       " 'farther',\n",
       " 'processessurfactants',\n",
       " 'adds',\n",
       " 'ting',\n",
       " 'package',\n",
       " 'oo']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_feature[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Features\n",
    "we calculate the chi-square metric between the target and the numerical variable and only select the variable with the maximum chi-squared values.\n",
    "\n",
    "$$ X^2 = \\sum\\frac{(O_i - E_i)^2}{E_i} $$\n",
    "$ X^2 $ = chi squared  \n",
    "$ O_i $ = observed value  \n",
    "$ E_i $ = expected value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def generate_chi_feature(X, y, num_feats):\n",
    "    X_norm = MinMaxScaler().fit_transform(X)\n",
    "    chi_selector = SelectKBest(chi2, k=num_feats)\n",
    "    chi_selector.fit(X_norm, y)\n",
    "    chi_support = chi_selector.get_support()\n",
    "    chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "    return chi_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 selected features\n"
     ]
    }
   ],
   "source": [
    "chi_feature = generate_chi_feature(X_ros, y_ros, 3000)\n",
    "print(str(len(chi_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['product',\n",
       " 'differences',\n",
       " 'pleasing',\n",
       " 'phases',\n",
       " 'seriously',\n",
       " 'surfucants',\n",
       " 'unfinished',\n",
       " 'splitting',\n",
       " 'reccomendations',\n",
       " 'recently']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_feature[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso: Select From Model\n",
    "Lasso's norm regularizer forces feature weights to be zero and so the higher the value of alpha the fewer features that have non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel #for selecting features\n",
    "from sklearn.linear_model import LogisticRegression #import the logistic regression model\n",
    "\n",
    "def generate_lr_feature(X, y, max_feats):\n",
    "    X_norm = MinMaxScaler().fit_transform(X)\n",
    "    lr_selector = SelectFromModel(LogisticRegression(solver=\"liblinear\", penalty=\"l1\", random_state=random_state), max_features=max_feats) #lasso regression uses L1 norm as regularizer and random_state to an integer to make sure examples are repeatable\n",
    "    lr_selector.fit(X_norm, y)\n",
    "    lr_support = lr_selector.get_support()\n",
    "    lr_feature = X.loc[:,lr_support].columns.tolist()\n",
    "    return lr_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685 selected features\n"
     ]
    }
   ],
   "source": [
    "lr_feature = generate_lr_feature(X_ros, y_ros, 3000)\n",
    "print(str(len(lr_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seriously',\n",
       " 'helpful',\n",
       " 'pam',\n",
       " 'oriented',\n",
       " 'se',\n",
       " 'yea',\n",
       " 'posssible',\n",
       " 'compared',\n",
       " 'requirements',\n",
       " 'aspects']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_feature[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-Based: Select From Model\n",
    "Random Forest calculates the final feature importance by taking the average of all decision tree feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def generate_rf_feature(X, y, max_feats):\n",
    "    rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=random_state), max_features=max_feats)\n",
    "    rf_selector.fit(X, y)\n",
    "    rf_support = rf_selector.get_support()\n",
    "    rf_feature = X.loc[:,rf_support].columns.tolist()\n",
    "    return rf_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053 selected features\n"
     ]
    }
   ],
   "source": [
    "rf_feature = generate_rf_feature(X_ros, y_ros, 3000)\n",
    "print(str(len(rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['product',\n",
       " 'seriously',\n",
       " 'comparison',\n",
       " 'helpful',\n",
       " 'half',\n",
       " 'pam',\n",
       " 'useful',\n",
       " 'checking',\n",
       " 'vague',\n",
       " 'find']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feature[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # for splitting the data into training and testing sets\n",
    "# split the data into 80% training and 20% testing, random_state to an integer ensures that the results are repeatable\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_ros,y_ros,train_size=0.8,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lr_model(X_train, X_test, y_train):\n",
    "    # penalty='none' implies no regularization and solver='lbfgs' is the default solver\n",
    "    model = LogisticRegression(solver='lbfgs', penalty='none', max_iter=4000, random_state=random_state)\n",
    "    # fit the training data to the model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    return model, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, y_pred_proba = generate_lr_model(X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score # import the score functions \n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(y_test, y_pred, axs=None, title=\"\", fontsize = 12):\n",
    "    ax = sns.heatmap(confusion_matrix(y_test, y_pred), cmap=\"Blues\", annot=True, linewidths=.5, ax=axs)\n",
    "    ax.set_title('Confusion Matrix' + title + \"\\n Accuracy: \" + str(accuracy_score(y_test, y_pred)), fontsize=fontsize) # add a title\n",
    "    ax.set_ylabel('Actual label') # add a ylabel\n",
    "    ax.set_xlabel('Predicted label') # add a xlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix \n",
    "plot_confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "cor_feature = generate_cor_feature(X_ros, y_ros, 1800)\n",
    "chi_feature = generate_chi_feature(X_ros, y_ros, 3500)\n",
    "lr_feature = generate_lr_feature(X_ros, y_ros, 600)\n",
    "rf_feature = generate_rf_feature(X_ros, y_ros, 700)\n",
    "\n",
    "# # Group features \n",
    "# cor_feature = generate_cor_feature(X_ros, y_ros, 200)\n",
    "# chi_feature = generate_chi_feature(X_ros, y_ros, 1200)\n",
    "# lr_feature = generate_lr_feature(X_ros, y_ros, 100)\n",
    "# rf_feature = generate_rf_feature(X_ros, y_ros, 500)\n",
    "\n",
    "features = [cor_feature, chi_feature, lr_feature, rf_feature]\n",
    "titles = [\"Pearson Correlation\", \"Chi-Squared\", \"Lasso Regression\", \"Random Forest\"]\n",
    "i_n = [0, 0, 1, 1]\n",
    "j_n = [0, 1, 0, 1]\n",
    "for i, j, feature, title in zip(i_n, j_n, features, titles):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_ros[[*feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "    model, y_pred, y_pred_proba = generate_lr_model(X_train, X_test, y_train)\n",
    "    full_title = \" for \" + title + \" features\"\n",
    "    plot_confusion_matrix(y_test, y_pred, axs[i, j], full_title, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For entire data frame\n",
    "Choosing 1800 Pearson Correlation features provides an accuracy of approximately 86% for the Logistic Regression model\n",
    "\n",
    "Choosing 3500 Chi-Squared features provides an accuracy of approximately 87% for the Logistic Regression model\n",
    "\n",
    "Choosing 600 Lasso Regression features provides an accuracy of approximately 92% for the Logistic Regression model\n",
    "\n",
    "Choosing 700 Random Forest features provides an accuracy of approximately 87% for the Logistic Regression model\n",
    "\n",
    "### For group 2\n",
    "Choosing 200 Pearson Correlation features provides an accuracy of approximately 82% for the Logistic Regression model\n",
    "\n",
    "Choosing 1200 Chi-Squared features provides an accuracy of approximately 87% for the Logistic Regression model\n",
    "\n",
    "Choosing 100 Lasso Regression features provides an accuracy of approximately 95% for the Logistic Regression model\n",
    "\n",
    "Choosing 500 Random Forest features provides an accuracy of approximately 87% for the Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes\n",
    "Naive Bayes algorithm based on Bayes’ theorem with the assumption of independence between every pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80% training and 20% testing, random_state to an integer ensures that the results are repeatable\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_ros,y_ros,train_size=0.8,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def generate_gnb_model(X_train, X_test, y_train):\n",
    "    model = GaussianNB() \n",
    "    # fit the training data to the model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    return model, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, y_pred_proba = generate_gnb_model(X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix \n",
    "plot_confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "cor_feature = generate_cor_feature(X_ros, y_ros, 4800)\n",
    "chi_feature = generate_chi_feature(X_ros, y_ros, 3500)\n",
    "lr_feature = generate_lr_feature(X_ros, y_ros, 700)\n",
    "rf_feature = generate_rf_feature(X_ros, y_ros, 900)\n",
    "\n",
    "# # Group features\n",
    "# cor_feature = generate_cor_feature(X_ros, y_ros, 700)\n",
    "# chi_feature = generate_chi_feature(X_ros, y_ros, 1000)\n",
    "# lr_feature = generate_lr_feature(X_ros, y_ros, 200)\n",
    "# rf_feature = generate_rf_feature(X_ros, y_ros, 200)\n",
    "\n",
    "features = [cor_feature, chi_feature, lr_feature, rf_feature]\n",
    "titles = [\"Pearson Correlation\", \"Chi-Squared\", \"Lasso Regression\", \"Random Forest\"]\n",
    "i_n = [0, 0, 1, 1]\n",
    "j_n = [0, 1, 0, 1]\n",
    "for i, j, feature, title in zip(i_n, j_n, features, titles):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_ros[[*feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "    model, y_pred, y_pred_proba = generate_gnb_model(X_train, X_test, y_train)\n",
    "    full_title = \" for \" + title + \" features\"\n",
    "    plot_confusion_matrix(y_test, y_pred, axs[i, j], full_title, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For entire data frame\n",
    "Choosing 4800 Pearson Correlation features provides an accuracy of approximately 88% for the Naive Bayes model\n",
    "\n",
    "Choosing 3500 Chi-Squared features provides an accuracy of approximately 90% for the Naive Bayes model\n",
    "\n",
    "Choosing 700 Lasso Regression features provides an accuracy of approximately 86% for the Naive Bayes model\n",
    "\n",
    "Choosing 900 Random Forest features provides an accuracy of approximately 84% for the Naive Bayes model\n",
    "\n",
    "### For group 2\n",
    "Choosing 700 Pearson Correlation features provides an accuracy of approximately 74% for the Naive Bayes model\n",
    "\n",
    "Choosing 1000 Chi-Squared features provides an accuracy of approximately 85% for the Naive Bayes model\n",
    "\n",
    "Choosing 200 Lasso Regression features provides an accuracy of approximately 85% for the Naive Bayes model\n",
    "\n",
    "Choosing 200 Random Forest features provides an accuracy of approximately 87% for the Naive Bayes model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80% training and 20% testing, random_state to an integer ensures that the results are repeatable\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_ros,y_ros,train_size=0.8,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def generate_dtc_model(X_train, X_test, y_train):\n",
    "    model = DecisionTreeClassifier(max_depth = 150, random_state=random_state) #random_state to an integer to make sure examples are repeatable\n",
    "    # fit the training data to the model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    return model, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, y_pred_proba = generate_dtc_model(X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix \n",
    "plot_confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "cor_feature = generate_cor_feature(X_ros, y_ros, 2800)\n",
    "chi_feature = generate_chi_feature(X_ros, y_ros, 3300)\n",
    "lr_feature = generate_lr_feature(X_ros, y_ros, 400)\n",
    "rf_feature = generate_rf_feature(X_ros, y_ros, 300)\n",
    "\n",
    "# Group features\n",
    "# cor_feature = generate_cor_feature(X_ros, y_ros, 300)\n",
    "# chi_feature = generate_chi_feature(X_ros, y_ros, 800)\n",
    "# lr_feature = generate_lr_feature(X_ros, y_ros, 100)\n",
    "# rf_feature = generate_rf_feature(X_ros, y_ros, 400)\n",
    "\n",
    "features = [cor_feature, chi_feature, lr_feature, rf_feature]\n",
    "titles = [\"Pearson Correlation\", \"Chi-Squared\", \"Lasso Regression\", \"Random Forest\"]\n",
    "i_n = [0, 0, 1, 1]\n",
    "j_n = [0, 1, 0, 1]\n",
    "for i, j, feature, title in zip(i_n, j_n, features, titles):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_ros[[*feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "    model, y_pred, y_pred_proba = generate_dtc_model(X_train, X_test, y_train)\n",
    "    full_title = \" for \" + title + \" features\"\n",
    "    plot_confusion_matrix(y_test, y_pred, axs[i, j], full_title, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For entire data frame\n",
    "Choosing 2800 Pearson Correlation features provides an accuracy of approximately 87% for the Decision Trees model\n",
    "\n",
    "Choosing 3300 Chi-Squared features provides an accuracy of approximately 85% for the Decision Trees model\n",
    "\n",
    "Choosing 400 Lasso Regression features provides an accuracy of approximately 87% for the Decision Trees model\n",
    "\n",
    "Choosing 300 Random Forest features provides an accuracy of approximately 85% for the Decision Trees model\n",
    "\n",
    "### For group 2\n",
    "Choosing 300 Pearson Correlation features provides an accuracy of approximately 82% for the Decision Trees model\n",
    "\n",
    "Choosing 800 Chi-Squared features provides an accuracy of approximately 82% for the Decision Trees model\n",
    "\n",
    "Choosing 100 Lasso Regression features provides an accuracy of approximately 85% for the Decision Trees model\n",
    "\n",
    "Choosing 400 Random Forest features provides an accuracy of approximately 85% for the Decision Trees model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80% training and 20% testing, random_state to an integer ensures that the results are repeatable\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_ros,y_ros,train_size=0.8,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def generate_rfc_model(X_train, X_test, y_train):\n",
    "    model = RandomForestClassifier(random_state=random_state) #random_state to an integer to make sure examples are repeatable\n",
    "    # fit the training data to the model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    return model, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, y_pred_proba = generate_rfc_model(X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix \n",
    "plot_confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "cor_feature = generate_cor_feature(X_ros, y_ros, 2800)\n",
    "chi_feature = generate_chi_feature(X_ros, y_ros, 5000)\n",
    "lr_feature = generate_lr_feature(X_ros, y_ros, 600)\n",
    "rf_feature = generate_rf_feature(X_ros, y_ros, 600)\n",
    "\n",
    "# # Group features\n",
    "# cor_feature = generate_cor_feature(X_ros, y_ros, 1300)\n",
    "# chi_feature = generate_chi_feature(X_ros, y_ros, 1200)\n",
    "# lr_feature = generate_lr_feature(X_ros, y_ros, 100)\n",
    "# rf_feature = generate_rf_feature(X_ros, y_ros, 100)\n",
    "\n",
    "features = [cor_feature, chi_feature, lr_feature, rf_feature]\n",
    "titles = [\"Pearson Correlation\", \"Chi-Squared\", \"Lasso Regression\", \"Random Forest\"]\n",
    "i_n = [0, 0, 1, 1]\n",
    "j_n = [0, 1, 0, 1]\n",
    "for i, j, feature, title in zip(i_n, j_n, features, titles):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_ros[[*feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "    model, y_pred, y_pred_proba = generate_rfc_model(X_train, X_test, y_train)\n",
    "    full_title = \" for \" + title + \" features\"\n",
    "    plot_confusion_matrix(y_test, y_pred, axs[i, j], full_title, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For entire data frame\n",
    "Choosing 2800 Pearson Correlation features provides an accuracy of approximately 87% for the Decision Trees model\n",
    "\n",
    "Choosing 5000 Chi-Squared features provides an accuracy of approximately 87% for the Decision Trees model\n",
    "\n",
    "Choosing 600 Lasso Regression features provides an accuracy of approximately 90% for the Decision Trees model\n",
    "\n",
    "Choosing 600 Random Forest features provides an accuracy of approximately 87% for the Decision Trees model\n",
    "\n",
    "### For group 2\n",
    "Choosing 1300 Pearson Correlation features provides an accuracy of approximately 85% for the Decision Trees model\n",
    "\n",
    "Choosing 1200 Chi-Squared features provides an accuracy of approximately 85% for the Decision Trees model\n",
    "\n",
    "Choosing 100 Lasso Regression features provides an accuracy of approximately 85% for the Decision Trees model\n",
    "\n",
    "Choosing 100 Random Forest features provides an accuracy of approximately 79% for the Decision Trees model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_feature_selection(model_type, iter_interval=100):\n",
    "    best_cor_acc = 0\n",
    "    best_cor_num = 0\n",
    "    best_chi_acc = 0\n",
    "    best_chi_num = 0\n",
    "    best_lr_acc = 0\n",
    "    best_lr_num = 0\n",
    "    best_rf_acc = 0\n",
    "    best_rf_num = 0\n",
    "    if model_type == 'lr':\n",
    "        for num_feats in range(iter_interval, len(word_set), iter_interval):\n",
    "            cor_feature = generate_cor_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*cor_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_lr_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_cor_acc:\n",
    "                best_cor_num = num_feats\n",
    "                best_cor_acc = accuracy\n",
    "            chi_feature = generate_chi_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*chi_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_lr_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_chi_acc:\n",
    "                best_chi_num = num_feats\n",
    "                best_chi_acc = accuracy\n",
    "            lr_feature = generate_lr_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*lr_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_lr_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_lr_acc:\n",
    "                best_lr_num = num_feats\n",
    "                best_lr_acc = accuracy\n",
    "            rf_feature = generate_rf_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*rf_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_lr_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_rf_acc:\n",
    "                best_rf_num = num_feats\n",
    "                best_rf_acc = accuracy\n",
    "\n",
    "    if model_type == 'gnb':\n",
    "        for num_feats in range(iter_interval, len(word_set), iter_interval):\n",
    "            cor_feature = generate_cor_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*cor_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_gnb_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_cor_acc:\n",
    "                best_cor_num = num_feats\n",
    "                best_cor_acc = accuracy\n",
    "            chi_feature = generate_chi_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*chi_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_gnb_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_chi_acc:\n",
    "                best_chi_num = num_feats\n",
    "                best_chi_acc = accuracy\n",
    "            lr_feature = generate_lr_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*lr_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_gnb_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_lr_acc:\n",
    "                best_lr_num = num_feats\n",
    "                best_lr_acc = accuracy\n",
    "            rf_feature = generate_rf_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*rf_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_gnb_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_rf_acc:\n",
    "                best_rf_num = num_feats\n",
    "                best_rf_acc = accuracy\n",
    "\n",
    "    if model_type == 'dtc':\n",
    "        for num_feats in range(iter_interval, len(word_set), iter_interval):\n",
    "            cor_feature = generate_cor_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*cor_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_dtc_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_cor_acc:\n",
    "                best_cor_num = num_feats\n",
    "                best_cor_acc = accuracy\n",
    "            chi_feature = generate_chi_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*chi_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_dtc_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_chi_acc:\n",
    "                best_chi_num = num_feats\n",
    "                best_chi_acc = accuracy\n",
    "            lr_feature = generate_lr_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*lr_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_dtc_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_lr_acc:\n",
    "                best_lr_num = num_feats\n",
    "                best_lr_acc = accuracy\n",
    "            rf_feature = generate_rf_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*rf_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_dtc_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_rf_acc:\n",
    "                best_rf_num = num_feats\n",
    "                best_rf_acc = accuracy\n",
    "\n",
    "    if model_type == 'rfc':\n",
    "        for num_feats in range(iter_interval, len(word_set), iter_interval):\n",
    "            cor_feature = generate_cor_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*cor_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_rfc_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_cor_acc:\n",
    "                best_cor_num = num_feats\n",
    "                best_cor_acc = accuracy\n",
    "            chi_feature = generate_chi_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*chi_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_rfc_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_chi_acc:\n",
    "                best_chi_num = num_feats\n",
    "                best_chi_acc = accuracy\n",
    "            lr_feature = generate_lr_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*lr_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_rfc_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_lr_acc:\n",
    "                best_lr_num = num_feats\n",
    "                best_lr_acc = accuracy\n",
    "            rf_feature = generate_rf_feature(X_ros, y_ros, num_feats)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_ros[[*rf_feature]],y_ros,train_size=0.8,random_state=random_state)\n",
    "            model, y_pred, y_pred_proba = generate_rfc_model(X_train, X_test, y_train)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_rf_acc:\n",
    "                best_rf_num = num_feats\n",
    "                best_rf_acc = accuracy\n",
    "\n",
    "    print(\"Best accuracy for Pearson Correlation features: \" + str(best_cor_acc) + \" with \" + str(best_cor_num) + \" features.\")\n",
    "    print(\"Best accuracy for Chi-Squared features: \" + str(best_chi_acc) + \" with \" + str(best_chi_num) + \" features.\")\n",
    "    print(\"Best accuracy for Lasso Regression features: \" + str(best_lr_acc) + \" with \" + str(best_lr_num) + \" features.\")\n",
    "    print(\"Best accuracy for Random Forest features: \" + str(best_rf_acc) + \" with \" + str(best_rf_num) + \" features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Level Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group_id_implementation'] = df['group_id'].astype(str) + df['implementation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(15, 5, figsize=(45, 90))\n",
    "for k, group_id in zip(range(75), df['group_id_implementation'].unique()):\n",
    "    i = k//5\n",
    "    j = k%5\n",
    "    temp = np.zeros((9), dtype=int)\n",
    "    temp_counts = df[df['group_id_implementation'] == group_id]['OutcomeScore'].value_counts()\n",
    "    for l in temp_counts.index:\n",
    "        temp[l] = temp_counts[l]\n",
    "    pd.Series(temp).plot(kind='bar', ax=axs[i , j])\n",
    "    axs[i, j].set_title(\"Team \" + str(group_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_group_lst = ['2d', '2g', '3b', '3e', '4b', '4i', '5b', '5c' '5e', '5i', '5o', '6l', '6m', '6n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['group_id_implementation'].isin(remove_group_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OutcomeScore'].value_counts().plot(kind='bar', title='Outcome Score Count'); "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dddc5c5a81e48ad3f744b019c0d1f35aaf38075c670d1e62af60b3c2f86184f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
